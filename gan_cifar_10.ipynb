{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "KMfVZDG9l6ZE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXwFZvHRuB9F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Utility Functions for Noise Generation, Label Encoding, and Image Display"
      ],
      "metadata": {
        "id": "404UZ584l-np"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_90v_JjuGEo"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def generate_noise(batch_size, noise_dim, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generates random noise vectors for the generator input.\n",
        "    \"\"\"\n",
        "    return torch.randn(batch_size, noise_dim, device=device)\n",
        "\n",
        "def one_hot_encode_labels(labels, num_classes):\n",
        "    \"\"\"\n",
        "    Converts label indices into one-hot encoded vectors.\n",
        "    \"\"\"\n",
        "    return F.one_hot(labels, num_classes)\n",
        "\n",
        "def combine_vectors(x, y):\n",
        "    \"\"\"\n",
        "    Combines two vectors by concatenating them along the specified dimension.\n",
        "    \"\"\"\n",
        "    return torch.cat((x.float(), y.float()), dim=1)\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(3, 32, 32), nrow=5, show=True):\n",
        "    \"\"\"\n",
        "    Displays a batch of images in a grid format.\n",
        "    \"\"\"\n",
        "    image_tensor = (image_tensor + 1) / 2  # Normalize to [0, 1]\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    if show:\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Generator Architecture for CIFAR-10 GAN\n"
      ],
      "metadata": {
        "id": "JsyTyOX7mBpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S22JBz7RxZ-L"
      },
      "outputs": [],
      "source": [
        "class CIFARGenerator(nn.Module):\n",
        "    def __init__(self, input_dim=110, image_channels=3, hidden_dim=64):\n",
        "        super(CIFARGenerator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_gen_block(input_dim, hidden_dim * 8, kernel_size=4, stride=1, padding=0),   # Output: (hidden_dim*8) x 4 x 4\n",
        "            self.make_gen_block(hidden_dim * 8, hidden_dim * 4, kernel_size=4, stride=2, padding=1), # Output: (hidden_dim*4) x 8 x 8\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=2, padding=1), # Output: (hidden_dim*2) x 16 x 16\n",
        "            self.make_gen_block(hidden_dim * 2, hidden_dim, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim) x 32 x 32\n",
        "            self.make_gen_block(hidden_dim, image_channels, kernel_size=3, stride=1, padding=1, final_layer=True), # Output: (image_channels) x 32 x 32\n",
        "        )\n",
        "\n",
        "    def make_gen_block(self, input_channels, output_channels, kernel_size=4, stride=2, padding=1, final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
        "                nn.Tanh(),\n",
        "            )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
        "        return self.gen(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Discriminator Architecture for CIFAR-10 GAN\n"
      ],
      "metadata": {
        "id": "-7OFcP5emI3v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyRm-HCdxczq"
      },
      "outputs": [],
      "source": [
        "class CIFARDiscriminator(nn.Module):\n",
        "    def __init__(self, image_channels=3, num_classes=10, hidden_dim=64):\n",
        "        super(CIFARDiscriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            # Input: (image_channels + num_classes) x 32 x 32\n",
        "            self.make_disc_block(image_channels + num_classes, hidden_dim),  # Output: hidden_dim x 16 x 16\n",
        "            self.make_disc_block(hidden_dim, hidden_dim * 2),                # Output: hidden_dim*2 x 8 x 8\n",
        "            self.make_disc_block(hidden_dim * 2, hidden_dim * 4),            # Output: hidden_dim*4 x 4 x 4\n",
        "            self.make_disc_block(hidden_dim * 4, 1, kernel_size=4, stride=1, padding=0, final_layer=True),  # Output: 1 x 1 x 1\n",
        "        )\n",
        "\n",
        "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, padding=1, final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride, padding),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            # Final layer without BatchNorm and with Sigmoid activation\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride, padding),\n",
        "                nn.Sigmoid(),\n",
        "            )\n",
        "\n",
        "    def forward(self, image):\n",
        "        disc_pred = self.disc(image)\n",
        "        return disc_pred.view(len(disc_pred), -1)  # Flatten to shape [batch_size, 1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CIFAR-10 Dataset and Define DataLoader\n"
      ],
      "metadata": {
        "id": "8j0-YDQGmMIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize all three channels\n",
        "])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "cifar_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "data_loader = DataLoader(cifar_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "elKl2_gikR_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Generator, Discriminator, and Optimizers\n"
      ],
      "metadata": {
        "id": "9455kvuDmO_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3m4EI8YykSt"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100\n",
        "num_classes = 10\n",
        "learning_rate = 0.0002\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = CIFARGenerator(input_dim=latent_dim + num_classes, image_channels=3).to(device)\n",
        "discriminator = CIFARDiscriminator(image_channels=3, num_classes=num_classes).to(device)\n",
        "\n",
        "gen_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the GAN Model or Generate Images Based on User Input"
      ],
      "metadata": {
        "id": "vNxOtl6amRqm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8_jDL8SB18z"
      },
      "outputs": [],
      "source": [
        "action = input(\"Enter 'train' to train the model or 'generate' to generate images: \").strip().lower()\n",
        "\n",
        "if action == 'train':\n",
        "    epochs = 200\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    print(\"Starting training from scratch.\")\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        epoch_num = epoch + 1  # To display epochs starting from 1\n",
        "        progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch_num}/{epochs}\")\n",
        "        for real, labels in progress_bar:\n",
        "            cur_batch_size = len(real)\n",
        "            real = real.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Create real labels (ones) and fake labels (zeros)\n",
        "            real_labels = torch.ones(cur_batch_size, 1, device=device)\n",
        "            fake_labels = torch.zeros(cur_batch_size, 1, device=device)\n",
        "\n",
        "            # Create one-hot labels and expand to match image dimensions\n",
        "            one_hot_labels = one_hot_encode_labels(labels, num_classes).float().to(device)\n",
        "            one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "            one_hot_labels = one_hot_labels.repeat(1, 1, 32, 32)\n",
        "\n",
        "            ### Update Discriminator ###\n",
        "            disc_optimizer.zero_grad()\n",
        "\n",
        "            # Concatenate real images with labels\n",
        "            real_input = torch.cat((real, one_hot_labels), dim=1)\n",
        "            real_output = discriminator(real_input)\n",
        "            real_loss = criterion(real_output, real_labels)\n",
        "\n",
        "            # Generate fake images\n",
        "            noise = generate_noise(cur_batch_size, latent_dim, device=device)\n",
        "            noise_and_labels = combine_vectors(noise, one_hot_encode_labels(labels, num_classes).to(device))\n",
        "            fake_images = generator(noise_and_labels)\n",
        "\n",
        "            # Concatenate fake images with labels\n",
        "            fake_input = torch.cat((fake_images.detach(), one_hot_labels), dim=1)\n",
        "            fake_output = discriminator(fake_input)\n",
        "            fake_loss = criterion(fake_output, fake_labels)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            disc_loss = real_loss + fake_loss\n",
        "            disc_loss.backward()\n",
        "            disc_optimizer.step()\n",
        "\n",
        "            ### Update Generator ###\n",
        "            gen_optimizer.zero_grad()\n",
        "\n",
        "            # Generate fake images again\n",
        "            noise = generate_noise(cur_batch_size, latent_dim, device=device)\n",
        "            noise_and_labels = combine_vectors(noise, one_hot_encode_labels(labels, num_classes).to(device))\n",
        "            fake_images = generator(noise_and_labels)\n",
        "\n",
        "            # Concatenate fake images with labels\n",
        "            fake_input = torch.cat((fake_images, one_hot_labels), dim=1)\n",
        "            fake_output = discriminator(fake_input)\n",
        "            gen_loss = criterion(fake_output, real_labels)\n",
        "            gen_loss.backward()\n",
        "            gen_optimizer.step()\n",
        "\n",
        "            # Optionally, update progress bar with losses\n",
        "            progress_bar.set_postfix({\n",
        "                'D_loss': f'{disc_loss.item():.4f}',\n",
        "                'G_loss': f'{gen_loss.item():.4f}'\n",
        "            })\n",
        "\n",
        "        # Print losses at every epoch\n",
        "        print(f\"Epoch [{epoch_num}/{epochs}] Discriminator Loss: {disc_loss.item():.4f} Generator Loss: {gen_loss.item():.4f}\")\n",
        "\n",
        "        # Show real and fake images for the first 3 epochs and then every 10 epochs\n",
        "        if epoch_num <= 3 or epoch_num % 10 == 0:\n",
        "            print(\"Real Images:\")\n",
        "            show_tensor_images(real, num_images=25, size=(3, 32, 32))\n",
        "            print(\"Fake Images:\")\n",
        "            show_tensor_images(fake_images, num_images=25, size=(3, 32, 32))\n",
        "\n",
        "        # Save checkpoint after every 10 epochs\n",
        "        if epoch_num % 10 == 0:\n",
        "            generator_file = f'cifar_generator_epoch_{epoch_num}.pth'\n",
        "            discriminator_file = f'cifar_discriminator_epoch_{epoch_num}.pth'\n",
        "            torch.save(generator.state_dict(), generator_file)\n",
        "            torch.save(discriminator.state_dict(), discriminator_file)\n",
        "            print(f\"Weights saved for generator and discriminator at epoch {epoch_num}.\")\n",
        "\n",
        "elif action == 'generate':\n",
        "    # Generate images\n",
        "    epoch = input(\"Enter the epoch number for the saved generator weights (e.g., '10', '20', '30', etc.): \").strip()\n",
        "    weight_file = f'cifar_generator_epoch_{epoch}.pth'\n",
        "\n",
        "    if os.path.exists(weight_file):\n",
        "        generator.load_state_dict(torch.load(weight_file, map_location=device))\n",
        "        generator.eval()\n",
        "\n",
        "        # Ask the user to input which object/class they want to generate\n",
        "        print(\"Enter the number corresponding to the object you want to generate:\")\n",
        "        print(\"0: Airplane, 1: Automobile, 2: Bird, 3: Cat, 4: Deer\")\n",
        "        print(\"5: Dog, 6: Frog, 7: Horse, 8: Ship, 9: Truck\")\n",
        "\n",
        "        class_number = int(input(\"Enter a number between 0 and 9: \").strip())\n",
        "        if class_number < 0 or class_number >= num_classes:\n",
        "            print(\"Invalid class number. Please enter a number between 0 and 9.\")\n",
        "        else:\n",
        "            # Generate images for the selected class\n",
        "            noise = generate_noise(25, latent_dim, device=device)\n",
        "            labels = torch.full((25,), class_number, device=device, dtype=torch.long)\n",
        "            one_hot_labels = one_hot_encode_labels(labels, num_classes).to(device)\n",
        "            noise_and_labels = combine_vectors(noise, one_hot_labels)\n",
        "            fake_images = generator(noise_and_labels)\n",
        "\n",
        "            # Show generated images\n",
        "            print(f\"Generated Images for class {class_number}:\")\n",
        "            show_tensor_images(fake_images, num_images=25, size=(3, 32, 32))\n",
        "    else:\n",
        "        print(f\"Weight file '{weight_file}' not found. Please train the model first.\")\n",
        "else:\n",
        "    print(\"Invalid input. Please enter 'train' or 'generate'.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}